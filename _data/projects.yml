- name: "Large-Scale Volumetric Mesh Visualization and Analysis"
  url: ./projects/projects-online-01.pdf
  text: 'Very large volumetric meshes are of crucial importance in many areas such as large-scale computational fluid dynamics (CFD) simulations, whether for car engine design or for simulating oil and gas reservoirs. Recent computational advances have led to computational grids of extreme size, such as trillion-cell reservoir simulations. The size and complexity of such grids pose a tremendous challenge to interactive visualization and analysis, and require the development of novel data structures for visualization, e.g., polyhedral grid data structures, as well as data structures for efficient querying and analysis.'
  image: './images/projects/cells.png'
  pdf: './projects/projects-online-01.pdf'

- name: "Differential Geometry and Mathematical Physics for Visualization and Analysis"
  url: ./projects/projects-online-02.pdf
  text: 'Differential geometry provides a powerful mathematical framework for describing physical processes from cosmology and general relativity to planet-scale fluid flow, such as large-scale eddies in the oceans or hurricanes, whether on Earth or on Jupiter. The combination of modern differential geometry, such as exterior calculus/differential forms and Riemannian geometry, mathematical physics, and scientific visualization is a very exciting area where modern differential geometric methods can help achieve a very high degree of generality, for example generalizing and unifying flow analysis from flat Euclidean space to curved manifolds such as the Earth’s surface. (Image by NASA/Goddard Space Flight Center Scientific Visualization Studio.)'
  image: './images/projects/differential02.jpg'
  pdf: './projects/projects-online-02.pdf'

- name: "Visualization for Nano-Scale Neuroscience"
  url: ./projects/projects-online-03.pdf
  text: 'Reconstructing the anatomical and functional connectivity of the brain has become one of the most active research areas in neuroscience. By ultimately mapping and deciphering a human’s entire connectome, i.e., the full “wiring diagram” of the brain comprising billions of neurons and their interconnections, scientists hope to gain an understanding of how the brain develops and functions, and how pathologies develop or can be treated. To support these goals, high-throughput methods for neural imaging have been developed. A major challenge going forward, however, is the lack of sufficiently powerful tools for interactive visualization and analysis. We design and develop prototype tools for tackling this challenge and help neuroscientists answer fundamental questions about our brain. Representative examples of our work are Abstractocyte for understanding astroglial cells, NeuroLines for interactive neuronal connectivity analysis, and ConnectomeExplorer for answering domain-specific questions using visual queries.'
  image: './images/projects/connectome.png'
  pdf: './projects/projects-online-03.pdf'

- name: "Visual Languages for Parallel Computing"
  url: ./projects/projects-online-04.pdf
  text: 'Many modern computational problems are inherently massively data-parallel. Research areas such as simulation, data-science and visual computing are increasingly dealing with data-parallel problems. For instance in visual computing parallel algorithms are needed for image processing, geometry processing, visualization, computational imaging, and many other subfields where the data primitives are parallel. In this project we develop novel domain specific languages that offer visual abstractions of different aspects of the programs. The parallel program development is aided by instantaneous visualizations of the underlying primitives of the algorithms. For instance in fluid simulation the parallel data primitives can be equipped with semantics like “particle” or “vector” which leads to different instantaneous visualizations. The development of better parallel programming languages is a research field with increasing importance as most modern computational problems need to be tackled with data-parallel algorithms.'
  image: './images/projects/visualdsl.png'
  pdf: './projects/projects-online-04.pdf'
  
- name: "CPU-Based Rendering of Large-Scale Particle Data"
  url: './projects/projects-online-07.pdf'
  text: 'Molecular dynamics simulations are crucial to investigating important processes in physics and thermodynamics. The simulated atoms are usually visualized as hard spheres with local lighting, like Phong or Lambert shading, where individual particles and their local density as well as larger structures can be perceived well in close-up views. However, for large-scale simulations with hundreds of millions of particles, the visualization usually suffers from strong aliasing artifacts. The mismatch between data size and output resolution leads to severe under-sampling of the geometry. This makes exploration of unknown data and detection of interesting phenomena via a top-down approach difficult.  We introduced the novel concept of screen-space normal distribution functions (S-NDFs) for particle data. S-NDFs represent the distribution of surface normals that map to a given pixel in screen space, which enables high-quality re-lighting without re-rendering particles.'
  image: './images/projects/largescaleparticle.jpg'
  pdf: './projects/projects-online-07.pdf'
  
- name: "Machine Learning and Data Mining from Large-Scale Volumetric Data"
  url: './projects/projects-online-06.pdf'
  text: 'Large-scale simulations result in enormous amounts of data. Visualization or even just transfer of the complete simulation data is a time consuming and tedious task. Extracting the essential part of the data is usually done after the entire simulation is finished. Since the storage capacity of the simulation servers is limited, not all data can be permanently stored and is only available during the simulation itself. Domain scientists are typically scanning the stored results looking for specific features in the data. The essential data covers just a tiny amount of the entire data space. Our approach attempts to detect features concurrently to the simulation. Due to temporal as well as spatial data coherence, similar patterns can be detected and stored in dictionaries. In the optimal case the original data can be reconstructed by a linear combination of a small amount of dictionary entries.'
  image: './images/projects/largescaledatamining.jpg'
  pdf: './projects/projects-online-06.pdf'
  
- name: "In-Situ Visualization of Large Scale Simulation Data"
  url:  './projects/projects-online-05.pdf'
  text: 'This project investigates techniques for in-situ visualization of large time-dependent volume data. Since state of the art large scale simulations can generate petabytes of data, not all data can be stored to permanent storage media. Usually the spatial dimensions are downscaled or only a small subset of the temporal series is stored. Our approach to in-situ visualization analyzes the results as simulation time progresses and extracts the essential data characteristics from the preliminary results. Very low data transfer rates can be achieved by exploiting temporal coherence of successive simulation timesteps. Only a small subset of the data is transferred progressively to the visualization client. The reconstruction of the data in an early stage of the simulation run, combined with interactive steering approaches, reduces the risk of running unnecessary simulations and enables the informed modification of simulation parameters.'
  image: './images/projects/insitu.png'
  pdf: './projects/projects-online-05.pdf'